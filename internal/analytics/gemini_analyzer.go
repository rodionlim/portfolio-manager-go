package analytics

import (
	"context"
	"fmt"
	"os"
	"path/filepath"
	"strings"
	"time"

	"google.golang.org/genai"
)

// GeminiAnalyzer implements the AIAnalyzer interface using Google's Gemini API
type GeminiAnalyzer struct {
	client *genai.Client
	model  string
}

// NewGeminiAnalyzer creates a new Gemini AI analyzer
func NewGeminiAnalyzer(ctx context.Context, apiKey string) (AIAnalyzer, error) {
	client, err := genai.NewClient(ctx, &genai.ClientConfig{
		APIKey: apiKey,
	})
	if err != nil {
		return nil, fmt.Errorf("failed to create Gemini client: %w", err)
	}

	return &GeminiAnalyzer{
		client: client,
		model:  "gemini-1.5-flash", // Using the latest model
	}, nil
}

// AnalyzeDocument analyzes a document and returns insights
func (g *GeminiAnalyzer) AnalyzeDocument(ctx context.Context, filePath string, fileType string) (*ReportAnalysis, error) {
	// Read the file
	fileData, err := os.ReadFile(filePath)
	if err != nil {
		return nil, fmt.Errorf("failed to read file %s: %w", filePath, err)
	}

	// Determine MIME type based on file extension
	mimeType := getMimeType(fileType)

	// Create the prompt for analysis
	prompt := `Please analyze this financial report and provide:
1. A comprehensive summary (2-3 paragraphs)
2. Key insights and findings (list format)
3. Important trends or patterns
4. Notable data points or metrics
5. Any significant changes from previous reports (if mentioned)

Focus on financial metrics, market trends, fund flows, trading volumes, and any strategic insights.
Be specific and include numerical data where available.`

	// Create content parts for the request
	contents := []*genai.Content{
		{
			Parts: []*genai.Part{
				genai.NewPartFromText(prompt),
				genai.NewPartFromBytes(fileData, mimeType),
			},
			Role: genai.RoleUser,
		},
	}

	// Create generation config
	config := &genai.GenerateContentConfig{
		Temperature:     genai.Ptr(float32(0.1)), // Lower temperature for more consistent analysis
		MaxOutputTokens: 2048,
	}

	// Generate content
	resp, err := g.client.Models.GenerateContent(ctx, g.model, contents, config)
	if err != nil {
		return nil, fmt.Errorf("failed to generate content: %w", err)
	}

	if len(resp.Candidates) == 0 || len(resp.Candidates[0].Content.Parts) == 0 {
		return nil, fmt.Errorf("no content generated by AI")
	}

	// Extract the analysis text
	var analysisText string
	for _, part := range resp.Candidates[0].Content.Parts {
		if part.Text != "" {
			analysisText += part.Text
		}
	}

	// Parse the analysis (this is a simplified parsing - in production you might want more sophisticated parsing)
	summary, keyInsights := parseAnalysisText(analysisText)

	// Extract filename for report title
	fileName := filepath.Base(filePath)
	reportTitle := strings.TrimSuffix(fileName, filepath.Ext(fileName))

	analysis := &ReportAnalysis{
		Summary:      summary,
		KeyInsights:  keyInsights,
		ReportDate:   time.Now().Unix(), // We'll update this when we have the actual report date
		ReportTitle:  reportTitle,
		ReportType:   fileType,
		FilePath:     filePath,
		AnalysisDate: time.Now().Unix(),
		Metadata: map[string]string{
			"analyzer":  "gemini-1.5-flash",
			"file_size": fmt.Sprintf("%d", len(fileData)),
			"mime_type": mimeType,
		},
	}

	return analysis, nil
}

// Close closes the Gemini client (no-op for this implementation)
func (g *GeminiAnalyzer) Close() error {
	// The client doesn't have a Close method in this version
	return nil
}

// getMimeType returns the appropriate MIME type for the file
func getMimeType(fileType string) string {
	switch strings.ToLower(fileType) {
	case "pdf":
		return "application/pdf"
	case "xlsx", "xls":
		return "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
	case "csv":
		return "text/csv"
	case "txt":
		return "text/plain"
	default:
		return "application/octet-stream"
	}
}

// parseAnalysisText parses the AI-generated analysis text into structured data
func parseAnalysisText(text string) (summary string, keyInsights []string) {
	lines := strings.Split(text, "\n")
	var summaryLines []string
	var insightLines []string

	inSummary := false
	inInsights := false

	for _, line := range lines {
		line = strings.TrimSpace(line)
		if line == "" {
			continue
		}

		// Look for section headers
		lowerLine := strings.ToLower(line)
		if strings.Contains(lowerLine, "summary") {
			inSummary = true
			inInsights = false
			continue
		} else if strings.Contains(lowerLine, "insight") || strings.Contains(lowerLine, "finding") || strings.Contains(lowerLine, "key") {
			inSummary = false
			inInsights = true
			continue
		} else if strings.Contains(lowerLine, "trend") || strings.Contains(lowerLine, "data point") || strings.Contains(lowerLine, "change") {
			inSummary = false
			inInsights = true
			continue
		}

		// Collect content
		if inSummary && !strings.HasPrefix(line, "-") && !strings.HasPrefix(line, "*") && !strings.HasPrefix(line, "•") {
			summaryLines = append(summaryLines, line)
		} else if inInsights || strings.HasPrefix(line, "-") || strings.HasPrefix(line, "*") || strings.HasPrefix(line, "•") {
			// Clean up bullet points
			cleaned := strings.TrimPrefix(line, "-")
			cleaned = strings.TrimPrefix(cleaned, "*")
			cleaned = strings.TrimPrefix(cleaned, "•")
			cleaned = strings.TrimSpace(cleaned)
			if cleaned != "" {
				insightLines = append(insightLines, cleaned)
			}
		}
	}

	// If we didn't find structured sections, use the whole text as summary and extract bullet points as insights
	if len(summaryLines) == 0 && len(insightLines) == 0 {
		// Split by paragraphs and bullet points
		paragraphs := strings.Split(text, "\n\n")
		for _, para := range paragraphs {
			para = strings.TrimSpace(para)
			if para == "" {
				continue
			}

			if strings.Contains(para, "-") || strings.Contains(para, "*") || strings.Contains(para, "•") {
				// This looks like a list of insights
				bulletLines := strings.Split(para, "\n")
				for _, bulletLine := range bulletLines {
					bulletLine = strings.TrimSpace(bulletLine)
					if strings.HasPrefix(bulletLine, "-") || strings.HasPrefix(bulletLine, "*") || strings.HasPrefix(bulletLine, "•") {
						cleaned := strings.TrimPrefix(bulletLine, "-")
						cleaned = strings.TrimPrefix(cleaned, "*")
						cleaned = strings.TrimPrefix(cleaned, "•")
						cleaned = strings.TrimSpace(cleaned)
						if cleaned != "" {
							insightLines = append(insightLines, cleaned)
						}
					}
				}
			} else {
				// This looks like summary text
				summaryLines = append(summaryLines, para)
			}
		}
	}

	summary = strings.Join(summaryLines, " ")
	if summary == "" {
		// Fallback: use first few sentences as summary
		sentences := strings.Split(text, ". ")
		if len(sentences) >= 2 {
			summary = strings.Join(sentences[:2], ". ") + "."
		} else {
			summary = text
		}
	}

	keyInsights = insightLines
	if len(keyInsights) == 0 {
		// Fallback: create some insights from the text
		keyInsights = []string{"Detailed analysis available in full summary"}
	}

	return summary, keyInsights
}
