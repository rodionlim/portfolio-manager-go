package analytics

import (
	"bytes"
	"context"
	"encoding/csv"
	"encoding/json"
	"fmt"
	"os"
	"path/filepath"
	"portfolio-manager/internal/dal"
	"portfolio-manager/pkg/logging"
	"portfolio-manager/pkg/types"
	"regexp"
	"strings"
	"time"

	"github.com/xuri/excelize/v2"
	"google.golang.org/genai"
)

type geminiStructuredResponse struct {
	Summary     string   `json:"summary"`
	KeyInsights []string `json:"keyInsights"`
}

// GeminiAnalyzer implements the AIAnalyzer interface using Google's Gemini API
type GeminiAnalyzer struct {
	client *genai.Client
	model  string
	db     dal.Database
}

// NewGeminiAnalyzer creates a new Gemini AI analyzer
func NewGeminiAnalyzer(ctx context.Context, apiKey string, model string) (AIAnalyzer, error) {
	client, err := genai.NewClient(ctx, &genai.ClientConfig{
		APIKey: apiKey,
	})
	if err != nil {
		return nil, fmt.Errorf("failed to create Gemini client: %w", err)
	}

	return &GeminiAnalyzer{
		client: client,
		model:  model,
	}, nil
}

// AnalyzeDocument analyzes a document and returns insights
func (g *GeminiAnalyzer) AnalyzeDocument(filePath string, fileType string) (*ReportAnalysis, error) {
	var fileData []byte
	var mimeType string
	var err error

	// Handle different file types
	switch strings.ToLower(fileType) {
	case "xlsx", "xls":
		// Convert XLSX to text format for Gemini
		textData, err := convertXLSXToText(filePath)
		if err != nil {
			return nil, fmt.Errorf("failed to convert XLSX to text: %w", err)
		}
		fileData = []byte(textData)
		mimeType = "text/plain"
	default:
		// Read other file types directly
		fileData, err = os.ReadFile(filePath)
		if err != nil {
			return nil, fmt.Errorf("failed to read file %s: %w", filePath, err)
		}
		mimeType = getMimeType(fileType)
	}

	// Create the prompt for analysis
	prompt := `You are a trading analyst. Read the attached “SGX Fund Flow Weekly Tracker” report and extract ONLY the most trade-relevant, easy-to-miss signals.

Return STRICT JSON ONLY (no markdown, no backticks, no extra text).

Schema:
{
	"summary": "string",
	"keyInsights": ["string", "string", ...]
}

Requirements:
- summary MUST be a TL;DR (max 5 lines). Each line should start with a short label, e.g. "Tone:", "Top sector:", "Top ticker:", "Divergence:", "Action:".
- keyInsights MUST be 3–6 short bullets (strings) with the most actionable points.
- Prefer institutional flows over retail flows; call out retail/institutional divergences.
- Use numbers and stock codes when available; if something is not present in the report, write "n/a" (do not guess).
- Do not restate tables.`

	// Create content parts for the request
	contents := []*genai.Content{
		{
			Parts: []*genai.Part{
				genai.NewPartFromText(prompt),
				genai.NewPartFromBytes(fileData, mimeType),
			},
			Role: genai.RoleUser,
		},
	}

	// Create generation config
	config := &genai.GenerateContentConfig{
		Temperature:     genai.Ptr(float32(0.1)), // Lower temperature for more consistent analysis
		MaxOutputTokens: 5000,                    // Keep output tight (TL;DR + bullets)
	}

	// Generate content
	resp, err := g.client.Models.GenerateContent(context.Background(), g.model, contents, config)
	if err != nil {
		return nil, fmt.Errorf("failed to generate content: %w", err)
	}

	if len(resp.Candidates) == 0 || len(resp.Candidates[0].Content.Parts) == 0 {
		return nil, fmt.Errorf("no content generated by AI")
	}

	// Extract the analysis text
	var analysisText string
	for _, part := range resp.Candidates[0].Content.Parts {
		if part.Text != "" {
			analysisText += part.Text
		}
	}

	// Parse the analysis. Prefer structured JSON output, with a fallback to heuristic parsing.
	logging.GetLogger().Info("AI Analysis Text: \n" + analysisText)

	var parsed geminiStructuredResponse
	summary := ""
	keyInsights := []string{}
	if err := json.Unmarshal([]byte(analysisText), &parsed); err == nil {
		summary = strings.TrimSpace(parsed.Summary)
		if parsed.KeyInsights != nil {
			keyInsights = parsed.KeyInsights
		}
	} else {
		logging.GetLogger().Warnf("AI response was not valid JSON; falling back to heuristic parsing: %v", err)
		summary, keyInsights = parseAnalysisText(analysisText)
		if keyInsights == nil {
			keyInsights = []string{}
		}
	}

	// Extract filename for report title
	fileName := filepath.Base(filePath)
	reportTitle := strings.TrimSuffix(fileName, filepath.Ext(fileName))

	// Extract report date from filename
	reportDate, err := extractReportDateFromFilename(fileName)
	if err != nil {
		reportDate = time.Now().Unix() // Fallback to current time if extraction fails
	}

	analysis := &ReportAnalysis{
		Summary:      summary,
		KeyInsights:  keyInsights,
		ReportDate:   reportDate,
		ReportTitle:  reportTitle,
		ReportType:   fileType,
		FilePath:     filePath,
		AnalysisDate: time.Now().Unix(),
		Metadata: map[string]string{
			"analyzer":  g.model,
			"file_size": fmt.Sprintf("%d", len(fileData)),
			"mime_type": mimeType,
		},
	}

	// Store analysis in LevelDB if database is available
	if g.db != nil {
		dbKey := fmt.Sprintf("%s:%s", types.AnalyticsSummaryKeyPrefix, fileName)
		if err := g.db.Put(dbKey, analysis); err != nil {
			// Log error but don't fail the analysis
			fmt.Printf("Warning: failed to store analysis in database: %v\n", err)
		}
	}

	return analysis, nil
}

// FetchAnalysisByFileName fetches analysis results by file name from the database
func (g *GeminiAnalyzer) FetchAnalysisByFileName(fileName string) (*ReportAnalysis, error) {
	if g.db == nil {
		return nil, fmt.Errorf("database not configured")
	}

	dbKey := fmt.Sprintf("%s:%s", types.AnalyticsSummaryKeyPrefix, fileName)
	var analysis ReportAnalysis
	err := g.db.Get(dbKey, &analysis)
	if err != nil {
		return nil, fmt.Errorf("analysis not found for file %s: %w", fileName, err)
	}

	return &analysis, nil
}

// GetAllAnalysisKeys gets all analysis keys from the database
func (g *GeminiAnalyzer) GetAllAnalysisKeys() ([]string, error) {
	if g.db == nil {
		return nil, fmt.Errorf("database not configured")
	}

	prefix := string(types.AnalyticsSummaryKeyPrefix)
	keys, err := g.db.GetAllKeysWithPrefix(prefix)
	if err != nil {
		return nil, fmt.Errorf("failed to get keys with prefix %s: %w", prefix, err)
	}

	return keys, nil
}

// Close closes the Gemini client (no-op for this implementation)
func (g *GeminiAnalyzer) Close() error {
	// The client doesn't have a Close method in this version
	return nil
}

// SetDatabase sets the database instance for storing analysis results
func (g *GeminiAnalyzer) SetDatabase(db dal.Database) {
	g.db = db
}

// extractReportDateFromFilename extracts the date from SGX filename format
// Example: "SGX_Fund_Flow_Weekly_Tracker_Week_of_26_May_2025.xlsx" -> "26_May_2025"
func extractReportDateFromFilename(filename string) (int64, error) {
	// Remove file extension
	nameWithoutExt := strings.TrimSuffix(filename, filepath.Ext(filename))

	// Regex to match the date pattern: dd_mmm_yyyy
	re := regexp.MustCompile(`(\d{1,2})_([A-Za-z]{3})_(\d{4})`)
	matches := re.FindStringSubmatch(nameWithoutExt)

	if len(matches) != 4 {
		return 0, fmt.Errorf("could not extract date from filename: %s", filename)
	}

	// Parse the date components
	day := matches[1]
	month := matches[2]
	year := matches[3]

	// Parse the date string
	dateStr := fmt.Sprintf("%s %s %s", day, month, year)
	parsedTime, err := time.Parse("2 Jan 2006", dateStr)
	if err != nil {
		return 0, fmt.Errorf("failed to parse date from filename: %w", err)
	}

	return parsedTime.Unix(), nil
}

// getMimeType returns the appropriate MIME type for the file
func getMimeType(fileType string) string {
	switch strings.ToLower(fileType) {
	case "pdf":
		return "application/pdf"
	case "csv":
		return "text/csv"
	case "txt":
		return "text/plain"
	case "html":
		return "text/html"
	case "css":
		return "text/css"
	case "xml":
		return "text/xml"
	case "rtf":
		return "text/rtf"
	case "md", "markdown":
		return "text/md"
	case "js", "javascript":
		return "application/x-javascript"
	case "py", "python":
		return "application/x-python"
	default:
		return "text/plain" // Default to plain text for better compatibility
	}
}

// parseAnalysisText parses the AI-generated analysis text into structured data
func parseAnalysisText(text string) (summary string, keyInsights []string) {
	lines := strings.Split(text, "\n")
	var summaryLines []string
	var insightLines []string

	inSummary := false
	inInsights := false

	for _, line := range lines {
		line = strings.TrimSpace(line)
		if line == "" {
			continue
		}

		// Look for section headers
		lowerLine := strings.ToLower(line)
		if strings.Contains(lowerLine, "summary") || strings.Contains(lowerLine, "concise summary") {
			inSummary = true
			inInsights = false
			continue
		} else if strings.Contains(lowerLine, "insight") || strings.Contains(lowerLine, "key insights") ||
			strings.Contains(lowerLine, "bullet") || strings.Contains(lowerLine, "recommendations") {
			inSummary = false
			inInsights = true
			continue
		}

		// Skip numbered headers like "1.", "2." etc
		if len(line) <= 3 && (strings.HasSuffix(line, ".") || strings.HasSuffix(line, ":")) {
			continue
		}

		// Collect content
		if inSummary && !strings.HasPrefix(line, "-") && !strings.HasPrefix(line, "*") && !strings.HasPrefix(line, "•") {
			summaryLines = append(summaryLines, line)
		} else if inInsights || strings.HasPrefix(line, "-") || strings.HasPrefix(line, "*") || strings.HasPrefix(line, "•") {
			// Clean up bullet points
			cleaned := strings.TrimPrefix(line, "-")
			cleaned = strings.TrimPrefix(cleaned, "*")
			cleaned = strings.TrimPrefix(cleaned, "•")
			cleaned = strings.TrimSpace(cleaned)
			if cleaned != "" && len(cleaned) > 5 { // Filter out very short lines
				insightLines = append(insightLines, cleaned)
			}
		}
	}

	// If we didn't find structured sections, use fallback parsing
	if len(summaryLines) == 0 && len(insightLines) == 0 {
		// Look for buy recommendations and institutional flow mentions
		paragraphs := strings.Split(text, "\n\n")
		var bestParagraph string
		var bestScore int

		for _, para := range paragraphs {
			para = strings.TrimSpace(para)
			if para == "" {
				continue
			}

			// Score paragraphs based on relevant keywords for holistic analysis
			score := 0
			lowerPara := strings.ToLower(para)
			if strings.Contains(lowerPara, "institutional") {
				score += 3
			}
			if strings.Contains(lowerPara, "ytd") || strings.Contains(lowerPara, "year-to-date") {
				score += 2
			}
			if strings.Contains(lowerPara, "weekly") && strings.Contains(lowerPara, "average") {
				score += 2
			}
			if strings.Contains(lowerPara, "divergence") || strings.Contains(lowerPara, "contrarian") {
				score += 2
			}
			if strings.Contains(lowerPara, "consistency") || strings.Contains(lowerPara, "persistent") {
				score += 2
			}
			if strings.Contains(lowerPara, "buy") || strings.Contains(lowerPara, "recommend") {
				score += 2
			}
			if strings.Contains(lowerPara, "retail") && strings.Contains(lowerPara, "institutional") {
				score += 1
			}
			if strings.Contains(lowerPara, "smart money") {
				score += 2
			}

			if score > bestScore && len(para) > 50 {
				bestScore = score
				bestParagraph = para
			}

			// Extract bullet points
			if strings.Contains(para, "-") || strings.Contains(para, "*") || strings.Contains(para, "•") {
				bulletLines := strings.Split(para, "\n")
				for _, bulletLine := range bulletLines {
					bulletLine = strings.TrimSpace(bulletLine)
					if strings.HasPrefix(bulletLine, "-") || strings.HasPrefix(bulletLine, "*") || strings.HasPrefix(bulletLine, "•") {
						cleaned := strings.TrimPrefix(bulletLine, "-")
						cleaned = strings.TrimPrefix(cleaned, "*")
						cleaned = strings.TrimPrefix(cleaned, "•")
						cleaned = strings.TrimSpace(cleaned)
						if cleaned != "" && len(cleaned) > 10 {
							insightLines = append(insightLines, cleaned)
						}
					}
				}
			}
		}

		if bestParagraph != "" {
			summaryLines = append(summaryLines, bestParagraph)
		}
	}

	summary = strings.Join(summaryLines, " ")
	if summary == "" {
		// Final fallback: look for the first substantial paragraph
		sentences := strings.Split(text, ". ")
		if len(sentences) >= 2 {
			summary = strings.Join(sentences[:2], ". ") + "."
		} else {
			summary = text
		}
	}

	keyInsights = insightLines
	if len(keyInsights) == 0 {
		// Extract key information as fallback with holistic approach
		if strings.Contains(strings.ToLower(text), "institutional") {
			keyInsights = []string{"Analyze institutional flow consistency across weekly and YTD timeframes for investment decisions"}
		} else {
			keyInsights = []string{"Consider multiple flow dimensions: weekly, YTD, retail divergence, and average daily patterns"}
		}
	}

	return summary, keyInsights
}

// convertXLSXToText converts an XLSX file to structured text format
// This handles multiple sheets and preserves the structure for AI analysis
func convertXLSXToText(filePath string) (string, error) {
	// Open the Excel file
	f, err := excelize.OpenFile(filePath)
	if err != nil {
		return "", fmt.Errorf("failed to open Excel file: %w", err)
	}
	defer func() {
		if err := f.Close(); err != nil {
			// Log the error but don't fail the function
		}
	}()

	var textBuilder strings.Builder

	// Get all sheet names
	sheetNames := f.GetSheetList()

	// Process each sheet
	for i, sheetName := range sheetNames {
		if i > 0 {
			textBuilder.WriteString("\n\n" + strings.Repeat("=", 80) + "\n")
		}
		textBuilder.WriteString(fmt.Sprintf("SHEET: %s\n", sheetName))
		textBuilder.WriteString(strings.Repeat("=", 80) + "\n\n")

		// Get all rows from the sheet
		rows, err := f.GetRows(sheetName)
		if err != nil {
			textBuilder.WriteString(fmt.Sprintf("Error reading sheet %s: %v\n", sheetName, err))
			continue
		}

		// Convert rows to CSV-like format for better structure
		csvBuffer := &bytes.Buffer{}
		csvWriter := csv.NewWriter(csvBuffer)

		// Write all rows to CSV buffer
		for _, row := range rows {
			// Skip completely empty rows
			if isEmptyRow(row) {
				continue
			}

			// Ensure all cells are strings and handle empty cells
			cleanRow := make([]string, len(row))
			for j, cell := range row {
				cleanRow[j] = strings.TrimSpace(cell)
			}

			if err := csvWriter.Write(cleanRow); err != nil {
				return "", fmt.Errorf("failed to write CSV row: %w", err)
			}
		}
		csvWriter.Flush()

		// Add the CSV content as structured text
		textBuilder.WriteString(csvBuffer.String())
		textBuilder.WriteString("\n")
	}

	return textBuilder.String(), nil
}

// isEmptyRow checks if a row contains only empty or whitespace-only cells
func isEmptyRow(row []string) bool {
	for _, cell := range row {
		if strings.TrimSpace(cell) != "" {
			return false
		}
	}
	return true
}
