package analytics

import (
	"bytes"
	"context"
	"encoding/csv"
	"fmt"
	"os"
	"path/filepath"
	"portfolio-manager/internal/dal"
	"portfolio-manager/pkg/types"
	"regexp"
	"strings"
	"time"

	"github.com/xuri/excelize/v2"
	"google.golang.org/genai"
)

// GeminiAnalyzer implements the AIAnalyzer interface using Google's Gemini API
type GeminiAnalyzer struct {
	client *genai.Client
	model  string
	db     dal.Database
}

// NewGeminiAnalyzer creates a new Gemini AI analyzer
func NewGeminiAnalyzer(ctx context.Context, apiKey string, model string) (AIAnalyzer, error) {
	client, err := genai.NewClient(ctx, &genai.ClientConfig{
		APIKey: apiKey,
	})
	if err != nil {
		return nil, fmt.Errorf("failed to create Gemini client: %w", err)
	}

	return &GeminiAnalyzer{
		client: client,
		model:  model,
	}, nil
}

// AnalyzeDocument analyzes a document and returns insights
func (g *GeminiAnalyzer) AnalyzeDocument(filePath string, fileType string) (*ReportAnalysis, error) {
	var fileData []byte
	var mimeType string
	var err error

	// Handle different file types
	switch strings.ToLower(fileType) {
	case "xlsx", "xls":
		// Convert XLSX to text format for Gemini
		textData, err := convertXLSXToText(filePath)
		if err != nil {
			return nil, fmt.Errorf("failed to convert XLSX to text: %w", err)
		}
		fileData = []byte(textData)
		mimeType = "text/plain"
	default:
		// Read other file types directly
		fileData, err = os.ReadFile(filePath)
		if err != nil {
			return nil, fmt.Errorf("failed to read file %s: %w", filePath, err)
		}
		mimeType = getMimeType(fileType)
	}

	// Create the prompt for analysis
	prompt := `Analyze this SGX fund flow report with HOLISTIC PERSPECTIVE focusing on institutional flows as smart money. Provide:

1. CONCISE SUMMARY (1 paragraph max):
   - Overall institutional vs retail flow dynamics (weekly + YTD trends)
   - Notable divergences between weekly and YTD patterns
   - 2 SPECIFIC BUY RECOMMENDATIONS based on: consistent institutional accumulation, favorable YTD trends, retail sentiment divergence, and average daily flow patterns

2. KEY INSIGHTS (max 5 bullet points):
   - Institutional flow consistency patterns (weekly vs YTD alignment)
   - Significant retail vs institutional divergences (contrarian opportunities)  
   - Average daily flow anomalies vs current week performance
   - Momentum shifts in institutional positioning
   - Sector-specific insights based on flow patterns
   - Risk signals from unusual flow patterns

Consider ALL data: weekly flows, YTD flows, retail behavior, average daily volumes, and flow consistency.
Treat institutional flows as smart money but analyze PERSISTENCE and CONSISTENCY, not just magnitude.
Be concise and actionable with specific stock codes.`

	// Create content parts for the request
	contents := []*genai.Content{
		{
			Parts: []*genai.Part{
				genai.NewPartFromText(prompt),
				genai.NewPartFromBytes(fileData, mimeType),
			},
			Role: genai.RoleUser,
		},
	}

	// Create generation config
	config := &genai.GenerateContentConfig{
		Temperature:     genai.Ptr(float32(0.1)), // Lower temperature for more consistent analysis
		MaxOutputTokens: 1024,                    // Reduced for more concise responses
	}

	// Generate content
	resp, err := g.client.Models.GenerateContent(context.Background(), g.model, contents, config)
	if err != nil {
		return nil, fmt.Errorf("failed to generate content: %w", err)
	}

	if len(resp.Candidates) == 0 || len(resp.Candidates[0].Content.Parts) == 0 {
		return nil, fmt.Errorf("no content generated by AI")
	}

	// Extract the analysis text
	var analysisText string
	for _, part := range resp.Candidates[0].Content.Parts {
		if part.Text != "" {
			analysisText += part.Text
		}
	}

	// Parse the analysis (this is a simplified parsing - in production you might want more sophisticated parsing)
	summary, keyInsights := parseAnalysisText(analysisText)

	// Extract filename for report title
	fileName := filepath.Base(filePath)
	reportTitle := strings.TrimSuffix(fileName, filepath.Ext(fileName))

	// Extract report date from filename
	reportDate, err := extractReportDateFromFilename(fileName)
	if err != nil {
		reportDate = time.Now().Unix() // Fallback to current time if extraction fails
	}

	analysis := &ReportAnalysis{
		Summary:      summary,
		KeyInsights:  keyInsights,
		ReportDate:   reportDate,
		ReportTitle:  reportTitle,
		ReportType:   fileType,
		FilePath:     filePath,
		AnalysisDate: time.Now().Unix(),
		Metadata: map[string]string{
			"analyzer":  g.model,
			"file_size": fmt.Sprintf("%d", len(fileData)),
			"mime_type": mimeType,
		},
	}

	// Store analysis in LevelDB if database is available
	if g.db != nil {
		dbKey := fmt.Sprintf("%s:%s", types.AnalyticsSummaryKeyPrefix, fileName)
		if err := g.db.Put(dbKey, analysis); err != nil {
			// Log error but don't fail the analysis
			fmt.Printf("Warning: failed to store analysis in database: %v\n", err)
		}
	}

	return analysis, nil
}

// FetchAnalysisByFileName fetches analysis results by file name from the database
func (g *GeminiAnalyzer) FetchAnalysisByFileName(fileName string) (*ReportAnalysis, error) {
	if g.db == nil {
		return nil, fmt.Errorf("database not configured")
	}

	dbKey := fmt.Sprintf("%s:%s", types.AnalyticsSummaryKeyPrefix, fileName)
	var analysis ReportAnalysis
	err := g.db.Get(dbKey, &analysis)
	if err != nil {
		return nil, fmt.Errorf("analysis not found for file %s: %w", fileName, err)
	}

	return &analysis, nil
}

// GetAllAnalysisKeys gets all analysis keys from the database
func (g *GeminiAnalyzer) GetAllAnalysisKeys() ([]string, error) {
	if g.db == nil {
		return nil, fmt.Errorf("database not configured")
	}

	prefix := string(types.AnalyticsSummaryKeyPrefix)
	keys, err := g.db.GetAllKeysWithPrefix(prefix)
	if err != nil {
		return nil, fmt.Errorf("failed to get keys with prefix %s: %w", prefix, err)
	}

	return keys, nil
}

// Close closes the Gemini client (no-op for this implementation)
func (g *GeminiAnalyzer) Close() error {
	// The client doesn't have a Close method in this version
	return nil
}

// SetDatabase sets the database instance for storing analysis results
func (g *GeminiAnalyzer) SetDatabase(db dal.Database) {
	g.db = db
}

// extractReportDateFromFilename extracts the date from SGX filename format
// Example: "SGX_Fund_Flow_Weekly_Tracker_Week_of_26_May_2025.xlsx" -> "26_May_2025"
func extractReportDateFromFilename(filename string) (int64, error) {
	// Remove file extension
	nameWithoutExt := strings.TrimSuffix(filename, filepath.Ext(filename))

	// Regex to match the date pattern: dd_mmm_yyyy
	re := regexp.MustCompile(`(\d{1,2})_([A-Za-z]{3})_(\d{4})`)
	matches := re.FindStringSubmatch(nameWithoutExt)

	if len(matches) != 4 {
		return 0, fmt.Errorf("could not extract date from filename: %s", filename)
	}

	// Parse the date components
	day := matches[1]
	month := matches[2]
	year := matches[3]

	// Parse the date string
	dateStr := fmt.Sprintf("%s %s %s", day, month, year)
	parsedTime, err := time.Parse("2 Jan 2006", dateStr)
	if err != nil {
		return 0, fmt.Errorf("failed to parse date from filename: %w", err)
	}

	return parsedTime.Unix(), nil
}

// getMimeType returns the appropriate MIME type for the file
func getMimeType(fileType string) string {
	switch strings.ToLower(fileType) {
	case "pdf":
		return "application/pdf"
	case "csv":
		return "text/csv"
	case "txt":
		return "text/plain"
	case "html":
		return "text/html"
	case "css":
		return "text/css"
	case "xml":
		return "text/xml"
	case "rtf":
		return "text/rtf"
	case "md", "markdown":
		return "text/md"
	case "js", "javascript":
		return "application/x-javascript"
	case "py", "python":
		return "application/x-python"
	default:
		return "text/plain" // Default to plain text for better compatibility
	}
}

// parseAnalysisText parses the AI-generated analysis text into structured data
func parseAnalysisText(text string) (summary string, keyInsights []string) {
	lines := strings.Split(text, "\n")
	var summaryLines []string
	var insightLines []string

	inSummary := false
	inInsights := false

	for _, line := range lines {
		line = strings.TrimSpace(line)
		if line == "" {
			continue
		}

		// Look for section headers
		lowerLine := strings.ToLower(line)
		if strings.Contains(lowerLine, "summary") || strings.Contains(lowerLine, "concise summary") {
			inSummary = true
			inInsights = false
			continue
		} else if strings.Contains(lowerLine, "insight") || strings.Contains(lowerLine, "key insights") ||
			strings.Contains(lowerLine, "bullet") || strings.Contains(lowerLine, "recommendations") {
			inSummary = false
			inInsights = true
			continue
		}

		// Skip numbered headers like "1.", "2." etc
		if len(line) <= 3 && (strings.HasSuffix(line, ".") || strings.HasSuffix(line, ":")) {
			continue
		}

		// Collect content
		if inSummary && !strings.HasPrefix(line, "-") && !strings.HasPrefix(line, "*") && !strings.HasPrefix(line, "•") {
			summaryLines = append(summaryLines, line)
		} else if inInsights || strings.HasPrefix(line, "-") || strings.HasPrefix(line, "*") || strings.HasPrefix(line, "•") {
			// Clean up bullet points
			cleaned := strings.TrimPrefix(line, "-")
			cleaned = strings.TrimPrefix(cleaned, "*")
			cleaned = strings.TrimPrefix(cleaned, "•")
			cleaned = strings.TrimSpace(cleaned)
			if cleaned != "" && len(cleaned) > 5 { // Filter out very short lines
				insightLines = append(insightLines, cleaned)
			}
		}
	}

	// If we didn't find structured sections, use fallback parsing
	if len(summaryLines) == 0 && len(insightLines) == 0 {
		// Look for buy recommendations and institutional flow mentions
		paragraphs := strings.Split(text, "\n\n")
		var bestParagraph string
		var bestScore int

		for _, para := range paragraphs {
			para = strings.TrimSpace(para)
			if para == "" {
				continue
			}

			// Score paragraphs based on relevant keywords for holistic analysis
			score := 0
			lowerPara := strings.ToLower(para)
			if strings.Contains(lowerPara, "institutional") {
				score += 3
			}
			if strings.Contains(lowerPara, "ytd") || strings.Contains(lowerPara, "year-to-date") {
				score += 2
			}
			if strings.Contains(lowerPara, "weekly") && strings.Contains(lowerPara, "average") {
				score += 2
			}
			if strings.Contains(lowerPara, "divergence") || strings.Contains(lowerPara, "contrarian") {
				score += 2
			}
			if strings.Contains(lowerPara, "consistency") || strings.Contains(lowerPara, "persistent") {
				score += 2
			}
			if strings.Contains(lowerPara, "buy") || strings.Contains(lowerPara, "recommend") {
				score += 2
			}
			if strings.Contains(lowerPara, "retail") && strings.Contains(lowerPara, "institutional") {
				score += 1
			}
			if strings.Contains(lowerPara, "smart money") {
				score += 2
			}

			if score > bestScore && len(para) > 50 {
				bestScore = score
				bestParagraph = para
			}

			// Extract bullet points
			if strings.Contains(para, "-") || strings.Contains(para, "*") || strings.Contains(para, "•") {
				bulletLines := strings.Split(para, "\n")
				for _, bulletLine := range bulletLines {
					bulletLine = strings.TrimSpace(bulletLine)
					if strings.HasPrefix(bulletLine, "-") || strings.HasPrefix(bulletLine, "*") || strings.HasPrefix(bulletLine, "•") {
						cleaned := strings.TrimPrefix(bulletLine, "-")
						cleaned = strings.TrimPrefix(cleaned, "*")
						cleaned = strings.TrimPrefix(cleaned, "•")
						cleaned = strings.TrimSpace(cleaned)
						if cleaned != "" && len(cleaned) > 10 {
							insightLines = append(insightLines, cleaned)
						}
					}
				}
			}
		}

		if bestParagraph != "" {
			summaryLines = append(summaryLines, bestParagraph)
		}
	}

	summary = strings.Join(summaryLines, " ")
	if summary == "" {
		// Final fallback: look for the first substantial paragraph
		sentences := strings.Split(text, ". ")
		if len(sentences) >= 2 {
			summary = strings.Join(sentences[:2], ". ") + "."
		} else {
			summary = text
		}
	}

	keyInsights = insightLines
	if len(keyInsights) == 0 {
		// Extract key information as fallback with holistic approach
		if strings.Contains(strings.ToLower(text), "institutional") {
			keyInsights = []string{"Analyze institutional flow consistency across weekly and YTD timeframes for investment decisions"}
		} else {
			keyInsights = []string{"Consider multiple flow dimensions: weekly, YTD, retail divergence, and average daily patterns"}
		}
	}

	return summary, keyInsights
}

// convertXLSXToText converts an XLSX file to structured text format
// This handles multiple sheets and preserves the structure for AI analysis
func convertXLSXToText(filePath string) (string, error) {
	// Open the Excel file
	f, err := excelize.OpenFile(filePath)
	if err != nil {
		return "", fmt.Errorf("failed to open Excel file: %w", err)
	}
	defer func() {
		if err := f.Close(); err != nil {
			// Log the error but don't fail the function
		}
	}()

	var textBuilder strings.Builder

	// Get all sheet names
	sheetNames := f.GetSheetList()

	// Process each sheet
	for i, sheetName := range sheetNames {
		if i > 0 {
			textBuilder.WriteString("\n\n" + strings.Repeat("=", 80) + "\n")
		}
		textBuilder.WriteString(fmt.Sprintf("SHEET: %s\n", sheetName))
		textBuilder.WriteString(strings.Repeat("=", 80) + "\n\n")

		// Get all rows from the sheet
		rows, err := f.GetRows(sheetName)
		if err != nil {
			textBuilder.WriteString(fmt.Sprintf("Error reading sheet %s: %v\n", sheetName, err))
			continue
		}

		// Convert rows to CSV-like format for better structure
		csvBuffer := &bytes.Buffer{}
		csvWriter := csv.NewWriter(csvBuffer)

		// Write all rows to CSV buffer
		for _, row := range rows {
			// Skip completely empty rows
			if isEmptyRow(row) {
				continue
			}

			// Ensure all cells are strings and handle empty cells
			cleanRow := make([]string, len(row))
			for j, cell := range row {
				cleanRow[j] = strings.TrimSpace(cell)
			}

			if err := csvWriter.Write(cleanRow); err != nil {
				return "", fmt.Errorf("failed to write CSV row: %w", err)
			}
		}
		csvWriter.Flush()

		// Add the CSV content as structured text
		textBuilder.WriteString(csvBuffer.String())
		textBuilder.WriteString("\n")
	}

	return textBuilder.String(), nil
}

// isEmptyRow checks if a row contains only empty or whitespace-only cells
func isEmptyRow(row []string) bool {
	for _, cell := range row {
		if strings.TrimSpace(cell) != "" {
			return false
		}
	}
	return true
}
